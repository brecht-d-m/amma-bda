{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BigQuery - Using Asynchronous APIs\n",
    "\n",
    "This notebook demonstrates how to use asynchronous versions of the pygcp.bigquery APIs from within a notebook.\n",
    "\n",
    "### In this notebook you will\n",
    "* Learn about the Query and Table APIs that have \\*_async versions\n",
    "* Learn how to use these APIs to return quickly so you can continue to do other work\n",
    "* Learn how to monitor the state of background async tasks and know when they are complete\n",
    "\n",
    "Related Links:\n",
    "\n",
    "* [BigQuery](https://cloud.google.com/bigquery/)\n",
    "\n",
    "----\n",
    "\n",
    "NOTE:\n",
    "\n",
    "* If you're new to notebooks, or want need an introduction to using BigQuery, check out the full [list](..) of notebooks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gcp.bigquery as bq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many if the APIs that exist on Query and Table objects in the gcp.bigquery library have async forms.\n",
    "\n",
    "These include:\n",
    "\n",
    "* Query.extract\n",
    "* Query.to_file\n",
    "* Query.execute\n",
    "* Table.load\n",
    "* Table.extract\n",
    "* Table.to_file\n",
    "* View.execute\n",
    "\n",
    "In each case, the signature is exactly the same; the only difference is that the async versions have an \\_async suffix on the method name and return Job objects.\n",
    "\n",
    "For example, the code below will attempt to extract the first 1000 rows of the natality sample table to a temporary file:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Job 27b548fa-6fc0-446a-bda3-64809a606402 in progress"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = bq.Table('publicdata:samples.natality')\n",
    "j = t.sample(count=1000).to_file_async('/tmp/natality1000.csv')\n",
    "j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the extract\\_async method returned a job with a GUID ID and a status. For a correct job on a very fast \n",
    "machine you may see 'completed' for the job status, but more likely you see 'in progress'.\n",
    "\n",
    "You can always check on the state of a job object by calling its is\\_complete method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j.is_complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To wait until a job completes we can call wait():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Job 27b548fa-6fc0-446a-bda3-64809a606402 completed"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once it is complete, the fatal\\_error property will tell us if a job failed, while the errors property will inform us of any non-fatal errors that may have occurred:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fatal: None\n",
      "Non-fatal: None\n"
     ]
    }
   ],
   "source": [
    "print \"Fatal: %s\" % str(j.fatal_error)\n",
    "print \"Non-fatal: %s\" % str(j.errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can call the Job.failed method to test for success:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j.failed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To see what happens with a failing job we can try a similar operation but with an extract using an invalid GCS name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobError: Invalid extract destination URI 'natality:invalid.csv'. Must be a valid Google Storage path.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  t = bq.Table('publicdata:samples.natality')\n",
    "  \n",
    "  # Note 'natality:invalid.csv' is an invalid name; specifically the ':' in the name.\n",
    "  j = t.sample(count=1000).extract_async('natality:invalid.csv')\n",
    "except Exception as e:\n",
    "  print \"%s: %s\" % (type(e).__name__, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how in this case we got a JobError exception.\n",
    "\n",
    "There are two useful utility functions in gcp.bigquery available for working with jobs, namely wait_any and wait_all. Each of these can take a reference to a job, or a list of jobs, plus an optional timeout. wait_any will return when at least one job has completed (or a timeout happens) while wait_all will return when all jobs have completed (or the timeout happens). In each case the return value is the list of complete jobs. We can illustrate this with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Job job__TzbEl2Sw8dCUZxNN3G_ECAyJxU completed, Job job_Hf4F_hqPehit_ATvV55P-i4W5Iw completed]\n"
     ]
    }
   ],
   "source": [
    "q1 = bq.Query('SELECT * FROM [publicdata:samples.natality] LIMIT 200')\n",
    "q2 = bq.Query('SELECT * FROM [publicdata:samples.natality] LIMIT 2000')\n",
    "j1 = q1.execute_async(use_cache=False)\n",
    "j2 = q2.execute_async(use_cache=False)\n",
    "\n",
    "while True:\n",
    "    completed = bq.wait_any([j1, j2])\n",
    "    print str(completed)\n",
    "    if len(completed) == 2:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
